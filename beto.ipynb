{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AdamW  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16dcff5f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_en</th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          review_en  \\\n",
       "0           0  One of the other reviewers has mentioned that ...   \n",
       "1           1  A wonderful little production. The filming tec...   \n",
       "2           2  I thought this was a wonderful way to spend ti...   \n",
       "3           3  Basically there's a family where a little boy ...   \n",
       "4           4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                           review_es sentiment sentimiento  \n",
       "0  Uno de los otros críticos ha mencionado que de...  positive    positivo  \n",
       "1  Una pequeña pequeña producción.La técnica de f...  positive    positivo  \n",
       "2  Pensé que esta era una manera maravillosa de p...  positive    positivo  \n",
       "3  Básicamente, hay una familia donde un niño peq...  negative    negativo  \n",
       "4  El \"amor en el tiempo\" de Petter Mattei es una...  positive    positivo  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenameDataset = \"datasets/IMDBDatasetSPANISH.csv\"\n",
    "data = pd.read_csv(filenameDataset)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "review_en      0\n",
       "review_es      0\n",
       "sentiment      0\n",
       "sentimiento    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(sentiment):    \n",
    "    sentiment = str(sentiment)    \n",
    "    if sentiment == 'positive':\n",
    "        return 1\n",
    "    elif sentiment == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check spanish\n",
    "def selectLanguage(language, data):\n",
    "    if language == \"spanish\":\n",
    "        data['is_positive'] = data.sentiment.apply(to_sentiment)\n",
    "        del data['review_en']\n",
    "        del data['sentimiento']\n",
    "        del data['sentiment']\n",
    "        data.columns = ['id_review', 'text', 'sentiment']\n",
    "    elif language == \"english\":\n",
    "        del data['review_es']\n",
    "        del data['sentimiento']\n",
    "        del data[data.columns[0]]\n",
    "        data.rename(columns={'review_en': 'text'}, inplace=True)\n",
    "        data['sentiment'] = data.sentiment.apply(to_sentiment)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(text):\n",
    "    text=re.sub(r'https?://www\\.\\S+\\.com','',text)\n",
    "    text=re.sub(r'[^A-Za-z|\\s]','',text)\n",
    "    text=re.sub(r'\\*+','swear',text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\" #emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\" #symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\" #transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\" #flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\" \n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_multiplechars(text):\n",
    "    text = re.sub(r'(.)\\1{3,}',r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def clean(df):\n",
    "    for col in ['text']:#,'selected_text']:\n",
    "        df[col]=df[col].astype(str).apply(lambda x:basic_cleaning(x))\n",
    "        df[col]=df[col].astype(str).apply(lambda x:remove_emoji(x))\n",
    "        df[col]=df[col].astype(str).apply(lambda x:remove_html(x))\n",
    "        df[col]=df[col].astype(str).apply(lambda x:remove_multiplechars(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idioma = \"spanish\"\n",
    "data = selectLanguage(idioma, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_review</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_review                                               text  sentiment\n",
       "0          0  Uno de los otros críticos ha mencionado que de...          1\n",
       "1          1  Una pequeña pequeña producción.La técnica de f...          1\n",
       "2          2  Pensé que esta era una manera maravillosa de p...          1\n",
       "3          3  Básicamente, hay una familia donde un niño peq...          0\n",
       "4          4  El \"amor en el tiempo\" de Petter Mattei es una...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    25000\n",
      "0    25000\n",
      "Name: sentiment, dtype: int64\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(data.sentiment.value_counts())\n",
    "print(len(data.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentDFTrain, commentDFVal = train_test_split(data, test_size=0.2, random_state=seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_review</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18165</th>\n",
       "      <td>18165</td>\n",
       "      <td>Esta película se ha comparado con la hilarante...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36059</th>\n",
       "      <td>36059</td>\n",
       "      <td>Razonablemente efectivo horror / ciencia ficci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13242</th>\n",
       "      <td>13242</td>\n",
       "      <td>La inspiración para las películas \"desnudas de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32985</th>\n",
       "      <td>32985</td>\n",
       "      <td>Cuando esta película se liberó originalmente, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41133</th>\n",
       "      <td>41133</td>\n",
       "      <td>Pasé por esto por casualidad. Estaba en la cas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43723</th>\n",
       "      <td>43723</td>\n",
       "      <td>Las figuras más grandes que la vida de Wyatt E...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>32511</td>\n",
       "      <td>De acuerdo, tienes: Penelope Keith como Miss H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5192</td>\n",
       "      <td>Una biótica extraña y intencional de Dyan Thom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>12172</td>\n",
       "      <td>Estructura básica de una historia: inicio, med...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>33003</td>\n",
       "      <td>Ubicado en París en el año 1910, un antiguo ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_review                                               text  sentiment\n",
       "18165      18165  Esta película se ha comparado con la hilarante...          0\n",
       "36059      36059  Razonablemente efectivo horror / ciencia ficci...          1\n",
       "13242      13242  La inspiración para las películas \"desnudas de...          1\n",
       "32985      32985  Cuando esta película se liberó originalmente, ...          1\n",
       "41133      41133  Pasé por esto por casualidad. Estaba en la cas...          1\n",
       "...          ...                                                ...        ...\n",
       "43723      43723  Las figuras más grandes que la vida de Wyatt E...          1\n",
       "32511      32511  De acuerdo, tienes: Penelope Keith como Miss H...          0\n",
       "5192        5192  Una biótica extraña y intencional de Dyan Thom...          0\n",
       "12172      12172  Estructura básica de una historia: inicio, med...          0\n",
       "33003      33003  Ubicado en París en el año 1910, un antiguo ca...          1\n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentDFTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_review</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>26247</td>\n",
       "      <td>Sin héroes muertos, se obtienen líneas estúpid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>35067</td>\n",
       "      <td>Pensé que tal vez ... tal vez esto podría ser ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>34590</td>\n",
       "      <td>Un equipo militar de élite americano que, por ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>16668</td>\n",
       "      <td>Ridículo cine de terror sobre un hombre rico (...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>12196</td>\n",
       "      <td>Bueno, si eres una de esas tuercas de cine de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49858</th>\n",
       "      <td>49858</td>\n",
       "      <td>Me gustó esta película.Eso es casi todo lo que...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19849</th>\n",
       "      <td>19849</td>\n",
       "      <td>Imagina la difícil situación de Richard, un pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46899</th>\n",
       "      <td>46899</td>\n",
       "      <td>Hay un problema inherente al comentar o revisa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28256</th>\n",
       "      <td>28256</td>\n",
       "      <td>Cuando la matriz apareció en 1999 y cuestionó ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43070</th>\n",
       "      <td>43070</td>\n",
       "      <td>Ohhhh hombre esta película es horrible! Este t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_review                                               text  sentiment\n",
       "26247      26247  Sin héroes muertos, se obtienen líneas estúpid...          0\n",
       "35067      35067  Pensé que tal vez ... tal vez esto podría ser ...          0\n",
       "34590      34590  Un equipo militar de élite americano que, por ...          0\n",
       "16668      16668  Ridículo cine de terror sobre un hombre rico (...          0\n",
       "12196      12196  Bueno, si eres una de esas tuercas de cine de ...          1\n",
       "...          ...                                                ...        ...\n",
       "49858      49858  Me gustó esta película.Eso es casi todo lo que...          1\n",
       "19849      19849  Imagina la difícil situación de Richard, un pi...          1\n",
       "46899      46899  Hay un problema inherente al comentar o revisa...          0\n",
       "28256      28256  Cuando la matriz apareció en 1999 y cuestionó ...          1\n",
       "43070      43070  Ohhhh hombre esta película es horrible! Este t...          0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentDFVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentDFTrain_clean = clean(commentDFTrain)\n",
    "commentDFVal_clean = clean(commentDFVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_review</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18165</th>\n",
       "      <td>18165</td>\n",
       "      <td>Esta pelcula se ha comparado con la hilarante ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36059</th>\n",
       "      <td>36059</td>\n",
       "      <td>Razonablemente efectivo horror  ciencia ficcin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13242</th>\n",
       "      <td>13242</td>\n",
       "      <td>La inspiracin para las pelculas desnudas de la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32985</th>\n",
       "      <td>32985</td>\n",
       "      <td>Cuando esta pelcula se liber originalmente se ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41133</th>\n",
       "      <td>41133</td>\n",
       "      <td>Pas por esto por casualidad Estaba en la casa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43723</th>\n",
       "      <td>43723</td>\n",
       "      <td>Las figuras ms grandes que la vida de Wyatt Ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>32511</td>\n",
       "      <td>De acuerdo tienes Penelope Keith como Miss Her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>5192</td>\n",
       "      <td>Una bitica extraa y intencional de Dyan Thomas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>12172</td>\n",
       "      <td>Estructura bsica de una historia inicio medio ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>33003</td>\n",
       "      <td>Ubicado en Pars en el ao  un antiguo cantante ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_review                                               text  sentiment\n",
       "18165      18165  Esta pelcula se ha comparado con la hilarante ...          0\n",
       "36059      36059  Razonablemente efectivo horror  ciencia ficcin...          1\n",
       "13242      13242  La inspiracin para las pelculas desnudas de la...          1\n",
       "32985      32985  Cuando esta pelcula se liber originalmente se ...          1\n",
       "41133      41133  Pas por esto por casualidad Estaba en la casa ...          1\n",
       "...          ...                                                ...        ...\n",
       "43723      43723  Las figuras ms grandes que la vida de Wyatt Ea...          1\n",
       "32511      32511  De acuerdo tienes Penelope Keith como Miss Her...          0\n",
       "5192        5192  Una bitica extraa y intencional de Dyan Thomas...          0\n",
       "12172      12172  Estructura bsica de una historia inicio medio ...          0\n",
       "33003      33003  Ubicado en Pars en el ao  un antiguo cantante ...          1\n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentDFTrain_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_review</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>26247</td>\n",
       "      <td>Sin hroes muertos se obtienen lneas estpidas c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>35067</td>\n",
       "      <td>Pens que tal vez  tal vez esto podra ser bueno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>34590</td>\n",
       "      <td>Un equipo militar de lite americano que por su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>16668</td>\n",
       "      <td>Ridculo cine de terror sobre un hombre rico Jo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>12196</td>\n",
       "      <td>Bueno si eres una de esas tuercas de cine de K...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49858</th>\n",
       "      <td>49858</td>\n",
       "      <td>Me gust esta pelculaEso es casi todo lo que pu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19849</th>\n",
       "      <td>19849</td>\n",
       "      <td>Imagina la difcil situacin de Richard un pinto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46899</th>\n",
       "      <td>46899</td>\n",
       "      <td>Hay un problema inherente al comentar o revisa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28256</th>\n",
       "      <td>28256</td>\n",
       "      <td>Cuando la matriz apareci en  y cuestion la exi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43070</th>\n",
       "      <td>43070</td>\n",
       "      <td>Oh hombre esta pelcula es horrible Este tipo d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_review                                               text  sentiment\n",
       "26247      26247  Sin hroes muertos se obtienen lneas estpidas c...          0\n",
       "35067      35067  Pens que tal vez  tal vez esto podra ser bueno...          0\n",
       "34590      34590  Un equipo militar de lite americano que por su...          0\n",
       "16668      16668  Ridculo cine de terror sobre un hombre rico Jo...          0\n",
       "12196      12196  Bueno si eres una de esas tuercas de cine de K...          1\n",
       "...          ...                                                ...        ...\n",
       "49858      49858  Me gust esta pelculaEso es casi todo lo que pu...          1\n",
       "19849      19849  Imagina la difcil situacin de Richard un pinto...          1\n",
       "46899      46899  Hay un problema inherente al comentar o revisa...          0\n",
       "28256      28256  Cuando la matriz apareci en  y cuestion la exi...          1\n",
       "43070      43070  Oh hombre esta pelcula es horrible Este tipo d...          0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentDFVal_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectTexts(dataSet, words):\n",
    "    list_text= []\n",
    "    list_label= []\n",
    "    for (text, target) in zip(dataSet.text, dataSet.sentiment):\n",
    "        if (len(text.split())) <= words:\n",
    "            list_text.append(text)\n",
    "            list_label.append(target)\n",
    "    DFTrain_clean = list(zip(list_text, list_label))\n",
    "    DFTrain_clean = pd.DataFrame(DFTrain_clean, columns=['text','sentiment'])\n",
    "    return DFTrain_clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentDFTrain_clean = selectTexts(commentDFTrain_clean, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Razonablemente efectivo horror  ciencia ficcin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Esta pelcula se fue a un comienzo interesanteS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toda la pelcula pareca sufrir de mala edicin c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Esta pelcula es absolutamente increbleDesde la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>En mi opinin esta pelcula tiene una iluminacin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>Muchas escenas divertidas sobre las personas q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>Esta es la pelcula para aquellos que creen que...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>Un ngulo inteligente y extrao para la belleza ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>Esta es una excelente pelcula Tom Hanks y Paul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>Obra maestraLa parte superior de la zanahoria ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3498 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     Razonablemente efectivo horror  ciencia ficcin...          1\n",
       "1     Esta pelcula se fue a un comienzo interesanteS...          0\n",
       "2     Toda la pelcula pareca sufrir de mala edicin c...          0\n",
       "3     Esta pelcula es absolutamente increbleDesde la...          1\n",
       "4     En mi opinin esta pelcula tiene una iluminacin...          1\n",
       "...                                                 ...        ...\n",
       "3493  Muchas escenas divertidas sobre las personas q...          1\n",
       "3494  Esta es la pelcula para aquellos que creen que...          1\n",
       "3495  Un ngulo inteligente y extrao para la belleza ...          1\n",
       "3496  Esta es una excelente pelcula Tom Hanks y Paul...          1\n",
       "3497  Obra maestraLa parte superior de la zanahoria ...          0\n",
       "\n",
       "[3498 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentDFTrain_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentDFVal_clean = selectTexts(commentDFVal_clean, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quieres saber lo que los escritores de esta pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Esta fue una pelcula muy bien guionadaGran div...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La pelcula no fue tan grandeEl libro es mejorP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He tenido que cambiar mi opinin sobre la peor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El mundo entero est cayendo presa de una enfer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Quin escribi el script para esta pelcula el pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Esta es la segunda pelcula que he visto de Ida...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Esta pelcula chupEl primero fue mucho mejorNad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Me encant esta pelcula lo vi cuando tena unos ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Admito que voy ms por el tradicional cuento de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment\n",
       "0    Quieres saber lo que los escritores de esta pe...          0\n",
       "1    Esta fue una pelcula muy bien guionadaGran div...          1\n",
       "2    La pelcula no fue tan grandeEl libro es mejorP...          1\n",
       "3    He tenido que cambiar mi opinin sobre la peor ...          0\n",
       "4    El mundo entero est cayendo presa de una enfer...          1\n",
       "..                                                 ...        ...\n",
       "887  Quin escribi el script para esta pelcula el pe...          0\n",
       "888  Esta es la segunda pelcula que he visto de Ida...          1\n",
       "889  Esta pelcula chupEl primero fue mucho mejorNad...          0\n",
       "890  Me encant esta pelcula lo vi cuando tena unos ...          1\n",
       "891  Admito que voy ms por el tradicional cuento de...          1\n",
       "\n",
       "[892 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentDFVal_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_size = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, dev_inputs, train_labels, dev_labels = train_test_split(\n",
    "    commentDFTrain_clean.text, \n",
    "    commentDFTrain_clean.sentiment, \n",
    "    test_size=dev_size, \n",
    "    stratify=commentDFTrain_clean.sentiment\n",
    ")\n",
    "#dev_...usare en train_an_epoch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2973"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678    Una pequea pelcula encantadora ubicada en el R...\n",
       "1881    Vi a esta pelcula ms de cien vecesEs realmente...\n",
       "917     Mal actu mal escrito y mal dirigidoLos efectos...\n",
       "3307    No hay un artculo artstico aqu porque no se me...\n",
       "2503    Medusa se atreve a ser veraz es una parodia es...\n",
       "                              ...                        \n",
       "331     Esta pelcula tiene efectos especiales que por ...\n",
       "2457    Gente por favor no te molestes en ver esta pel...\n",
       "2612    Esta fue una mirada bastante desconcertante a ...\n",
       "939     Esta debe ser una de las pelculas danas ms div...\n",
       "1349    Esta pelcula sirve a todos los estereotipos gr...\n",
       "Name: text, Length: 2973, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2973"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678    1\n",
       "1881    1\n",
       "917     0\n",
       "3307    0\n",
       "2503    1\n",
       "       ..\n",
       "331     1\n",
       "2457    0\n",
       "2612    1\n",
       "939     1\n",
       "1349    0\n",
       "Name: sentiment, Length: 2973, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3065    Este sinceramente dulce y laboriosamente ritmo...\n",
       "678     Esta es una excelente pelcula llena de complej...\n",
       "1445    Yo cuando un adolescente realmente disfrut de ...\n",
       "2364    Solo me gustara decir que la cura fue una pelc...\n",
       "700     Esta pelcula me hizo muy felizEs imposible no ...\n",
       "                              ...                        \n",
       "2978    Desde el principio hasta que haya estado en el...\n",
       "654     Pens que Hugh OConor era asombroso como el jov...\n",
       "3090    Esta es ciertamente una pelcula de calidad con...\n",
       "926     Aunque traje esta pelcula por accidente pens q...\n",
       "2418    Estoy de acuerdo en que esta pelcula desperdic...\n",
       "Name: text, Length: 525, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3065    0\n",
       "678     1\n",
       "1445    1\n",
       "2364    1\n",
       "700     1\n",
       "       ..\n",
       "2978    0\n",
       "654     1\n",
       "3090    1\n",
       "926     1\n",
       "2418    0\n",
       "Name: sentiment, Length: 525, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class createDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n",
    "    ds = createDataset(\n",
    "        texts=texts.to_numpy(),\n",
    "        targets=labels.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "  )\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0 #modifique y no se dio el error de createDataset\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "max_secuence_length = 80\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 16 #ya lo llamo mas arriba\n",
    "#train_data_loader = create_data_loader(train_inputs, train_labels, tokenizer, max_secuence_length, batch_size)\n",
    "train_data_loader = create_data_loader(train_inputs, train_labels, tokenizer, max_secuence_length, batch_size)\n",
    "#dev_data_loader = create_data_loader(dev_inputs, dev_labels, tokenizer, max_secuence_length, batch_size)\n",
    "dev_data_loader = create_data_loader(dev_inputs, dev_labels, tokenizer, max_secuence_length, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForMaskedLM, AdamW \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the model, modify it with the new classifier and return\n",
    "def delete_classifier(beto_model): \n",
    "    new_cls = nn.Sequential(\n",
    "#         nn.Linear(beto_model.config.hidden_size, 200)\n",
    "        nn.Linear(beto_model.config.hidden_size, 5),\n",
    "#         nn.BatchNorm1d(num_features=)\n",
    "        nn.Dropout(0.6),\n",
    "    )\n",
    "    \n",
    "    copyOfModel = copy.deepcopy(beto_model)\n",
    "    copyOfModel.cls = new_cls\n",
    "\n",
    "    return copyOfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model...\n",
    "class OrganicClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):  \n",
    "        super(OrganicClassifier, self).__init__()\n",
    "        \n",
    "        # modelo pre entrando...        \n",
    "        self.beto = delete_classifier(AutoModelForMaskedLM.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\"))\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            \n",
    "            \n",
    "#             nn.BatchNorm1d(num_features=200),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.6),\n",
    "            \n",
    "#             nn.Linear(200,100),\n",
    "#             nn.BatchNorm1d(num_features=100),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.6),\n",
    "            \n",
    "#             nn.Linear(100,50),\n",
    "#             nn.BatchNorm1d(num_features=50),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(p=0.35),\n",
    "            \n",
    "#             nn.Linear(50, n_classes),\n",
    "#             nn.Sigmoid()\n",
    "            \n",
    "            nn.BatchNorm1d(num_features=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            \n",
    "            nn.Linear(5, n_classes),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "  \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        secuence_output = self.beto(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )[0][:,0,:]\n",
    "        out = self.linear_layers(secuence_output)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OrganicClassifier(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jose/miniforge3/envs/myclone/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters...\n",
    "learning_rate = 1e-6\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, correct_bias=False)\n",
    "# optimizer =torch.optim.AdamW\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tareas a realizar durante una época para entrenar el modelo...\n",
    "def train_an_epoch(\n",
    "    model, \n",
    "    train_data_loader,\n",
    "    dev_data_loader,\n",
    "    criterion, \n",
    "    optimizer\n",
    "):\n",
    "\n",
    "   \n",
    "    running_loss = 0\n",
    "    running_accs = 0\n",
    "    steps = 0;\n",
    "    \n",
    "\n",
    "    for batch in train_data_loader:\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "       \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "        \n",
    "       \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "\n",
    "        targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, targets.float())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        acc = torch.eq(targets, outputs.round_()).float().mean()\n",
    "        running_loss = loss.item()\n",
    "        running_loss += loss.item();\n",
    "        running_accs += acc.item()\n",
    "        steps+=1\n",
    "            \n",
    "\n",
    "    loss = running_loss/steps;\n",
    "    acc = running_accs/steps;\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        epoch_accs_val=0;\n",
    "        steps_val=0;\n",
    "        \n",
    "        for batch in dev_data_loader:\n",
    "            \n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "        \n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "\n",
    "            targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "\n",
    "\n",
    "            acc_val = torch.eq(targets, outputs.round_()).float().mean();\n",
    "            epoch_accs_val += acc_val.item()\n",
    "            steps_val += 1\n",
    "            \n",
    "        val_acc = epoch_accs_val/steps_val\n",
    "    \n",
    "    return loss, acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo segun cantidad de epocas\n",
    "def train_the_model(epochs):\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        loss, acc, val_acc = train_an_epoch(\n",
    "            model, \n",
    "            train_data_loader,\n",
    "            dev_data_loader,\n",
    "            criterion, \n",
    "            optimizer            \n",
    "        )\n",
    "        \n",
    "        print('--------EPOCH SUMMARY---------')\n",
    "        print('Epoch ', e+1, ' training loss: ', loss)\n",
    "        print('Epoch ', e+1, ' training acc: ', acc*100, '%')\n",
    "        print('Epoch ', e+1, ' val acc: ', val_acc*100, '%')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra de graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir la función de Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "train_losses, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jose/miniforge3/envs/myclone/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jose/Documents/thesis/RecSys/beto.ipynb Cell 52\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y153sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(targets, (targets\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y153sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#outputs = outputs.round_() ## no funciono\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y153sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39;49mlogits \u001b[39m##\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y153sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#loss = criterion(outputs, targets.float())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y153sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, targets\u001b[39m.\u001b[39mfloat())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train() #\n",
    "    train_loss = 0.0 #\n",
    "   \n",
    "    #running_loss = 0\n",
    "    #running_accs = 0\n",
    "    #steps = 0;\n",
    "    \n",
    "    for batch in train_data_loader:      \n",
    "       \n",
    "        optimizer.zero_grad()       \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)       \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "        #outputs = outputs.round_() ## no funciono\n",
    "        logits = outputs.logits ## #tampoco funciona logits\n",
    "        #loss = criterion(outputs, targets.float())\n",
    "        loss = criterion(logits, targets.float())\n",
    "        #loss = outputs.loss #no funciono\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() #\n",
    "\n",
    "        #acc = torch.eq(targets, outputs.round_()).float().mean()\n",
    "        #running_loss = loss.item()\n",
    "        #running_loss += loss.item();\n",
    "        #running_accs += acc.item()\n",
    "        #steps+=1\n",
    "            \n",
    "\n",
    "    #loss = running_loss/steps;\n",
    "    #acc = running_accs/steps;\n",
    "    \n",
    "    train_losses.append(train_loss/len(train_data_loader)) #\n",
    "    model.eval() #\n",
    "    val_loss = 0.0 #\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #epoch_accs_val=0;\n",
    "        #steps_val=0;        \n",
    "        for batch in dev_data_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            #outputs = outputs.round_() ## no funciono\n",
    "            targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "            \n",
    "            logits = outputs.logits #tampoco funciona logits\n",
    "            #loss = criterion(outputs, targets) #\n",
    "            loss = criterion(logits, targets) #tampoco funciona logits \n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item() #\n",
    "\n",
    "            #acc_val = torch.eq(targets, outputs.round_()).float().mean();\n",
    "            #epoch_accs_val += acc_val.item()\n",
    "            #steps_val += 1\n",
    "            \n",
    "        #\n",
    "        #val_acc = epoch_accs_val/steps_val\n",
    "    \n",
    "    val_losses.append(val_loss / len(dev_data_loader)) #\n",
    "    print(f'Epoch [{epoch + 1}/{n_epochs}] --> Train Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}') #\n",
    "    early_stopping(val_losses[-1], model) #\n",
    "    #\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Deteniendo el entrenamiento temprano\")\n",
    "        break\n",
    "    #\n",
    "    #return loss, acc, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica del error en entrenamiento y validación por época\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tareas a realizar durante una época para entrenar el modelo...\n",
    "def train_an_epoch(\n",
    "    model, \n",
    "    train_data_loader,\n",
    "    dev_data_loader,\n",
    "    criterion, \n",
    "    optimizer,\n",
    "    n_epochs\n",
    "):\n",
    "\n",
    "   \n",
    "    running_loss = 0\n",
    "    running_accs = 0\n",
    "    steps = 0;\n",
    "    \n",
    "    train_loss = 0.0 #\n",
    "\n",
    "    for batch in train_data_loader:\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "       \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "        \n",
    "       \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "\n",
    "        targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, targets.float())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() #\n",
    "\n",
    "        acc = torch.eq(targets, outputs.round_()).float().mean()\n",
    "        running_loss = loss.item()\n",
    "        running_loss += loss.item();\n",
    "        running_accs += acc.item()\n",
    "        steps+=1\n",
    "            \n",
    "\n",
    "    loss = running_loss/steps;\n",
    "    acc = running_accs/steps;\n",
    "\n",
    "    train_losses.append(train_loss / len(train_loader)) #\n",
    "\n",
    "    val_loss = 0.0 #\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        epoch_accs_val=0;\n",
    "        steps_val=0;\n",
    "        \n",
    "        for batch in dev_data_loader:\n",
    "            \n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "        \n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "\n",
    "            targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "\n",
    "            loss = criterio(outputs, targets) #\n",
    "            val_loss += loss.item() #\n",
    "\n",
    "            acc_val = torch.eq(targets, outputs.round_()).float().mean();\n",
    "            epoch_accs_val += acc_val.item()\n",
    "            steps_val += 1\n",
    "            \n",
    "        val_acc = epoch_accs_val/steps_val\n",
    "    \n",
    "    val_losses.append(val_loss / len(dev_data_loader)) #\n",
    "    print(f'Epoch [{epoch + 1}/{n_epochs}] --> Train Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}') #\n",
    "    early_stopping(val_losses[-1], model) #\n",
    "\n",
    "\n",
    "    return loss, acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo segun cantidad de epocas\n",
    "def train_the_model(epochs):\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        loss, acc, val_acc = train_an_epoch(\n",
    "            model, \n",
    "            train_data_loader,\n",
    "            dev_data_loader,\n",
    "            criterion, \n",
    "            optimizer,\n",
    "            n_epochs\n",
    "        )\n",
    "        #\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Deteniendo el entrenamiento temprano\")\n",
    "            break\n",
    "        #\n",
    "        \n",
    "        print('--------EPOCH SUMMARY---------')\n",
    "        print('Epoch ', e+1, ' training loss: ', loss)\n",
    "        print('Epoch ', e+1, ' training acc: ', acc*100, '%')\n",
    "        print('Epoch ', e+1, ' val acc: ', val_acc*100, '%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jose/miniforge3/envs/myclone/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jose/Documents/thesis/RecSys/beto.ipynb Cell 50\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#epochs = 5 \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_the_model(n_epochs)\n",
      "\u001b[1;32m/Users/jose/Documents/thesis/RecSys/beto.ipynb Cell 50\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_the_model\u001b[39m(epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         loss, acc, val_acc \u001b[39m=\u001b[39m train_an_epoch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             model, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             train_data_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             dev_data_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             criterion, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             optimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             n_epochs\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39mif\u001b[39;00m early_stopping\u001b[39m.\u001b[39mearly_stop:\n",
      "\u001b[1;32m/Users/jose/Documents/thesis/RecSys/beto.ipynb Cell 50\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m loss \u001b[39m=\u001b[39m running_loss\u001b[39m/\u001b[39msteps;\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m acc \u001b[39m=\u001b[39m running_accs\u001b[39m/\u001b[39msteps;\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(train_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader)) \u001b[39m#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jose/Documents/thesis/RecSys/beto.ipynb#Y136sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "#epochs = 5 \n",
    "train_the_model(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica del error en entrenamiento y validación por época\n",
    "plt.plot(train_losses, label='Training Loss') #\n",
    "plt.plot(val_losses, label='Validation Loss') #\n",
    "plt.xlabel('Epoch') #\n",
    "plt.ylabel('Loss') #\n",
    "plt.legend() #\n",
    "plt.show() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra de graficos 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "# Inicializa EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=5, delta=0.001)\n",
    "# Listas para almacenar la pérdida en entrenamiento y validación\n",
    "train_losses, val_losses = [], []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.delta = delta\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jose/miniforge3/envs/myclone/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------EPOCH SUMMARY---------\n",
      "Epoch  1  training loss:  0.006937780046975741\n",
      "Epoch  1  training acc:  55.74079819263951 %\n",
      "Epoch  1  val acc:  55.783799561587244 %\n",
      "--------EPOCH SUMMARY---------\n",
      "Epoch  2  training loss:  0.007909825412175988\n",
      "Epoch  2  training acc:  55.63223740105988 %\n",
      "Epoch  2  val acc:  58.20221449389602 %\n",
      "--------EPOCH SUMMARY---------\n",
      "Epoch  3  training loss:  0.007170344552686138\n",
      "Epoch  3  training acc:  57.56306866163848 %\n",
      "Epoch  3  val acc:  57.77972033529571 %\n",
      "--------EPOCH SUMMARY---------\n",
      "Epoch  4  training loss:  0.007452239913325156\n",
      "Epoch  4  training acc:  58.790839551597514 %\n",
      "Epoch  4  val acc:  59.105477911053285 %\n",
      "--------EPOCH SUMMARY---------\n",
      "Epoch  5  training loss:  0.00666170927786058\n",
      "Epoch  5  training acc:  58.444478915583694 %\n",
      "Epoch  5  val acc:  59.6736597292351 %\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    running_accs = 0\n",
    "    steps = 0;\n",
    "    for batch in train_data_loader:\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "       \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        targets = batch[\"targets\"].to(device)\n",
    "        \n",
    "       \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "\n",
    "        targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "        \n",
    "\n",
    "        loss = criterion(outputs, targets.float())\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        acc = torch.eq(targets, outputs.round_()).float().mean()\n",
    "        running_loss = loss.item()\n",
    "        running_loss += loss.item();\n",
    "        running_accs += acc.item()\n",
    "        steps+=1\n",
    "            \n",
    "\n",
    "    loss = running_loss/steps;\n",
    "    acc = running_accs/steps;\n",
    "    train_losses.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        epoch_accs_val=0;\n",
    "        steps_val=0;\n",
    "        \n",
    "        for batch in dev_data_loader:\n",
    "            \n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            targets = batch[\"targets\"].to(device)\n",
    "        \n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "\n",
    "            targets = torch.reshape(targets, (targets.shape[0], 1))\n",
    "\n",
    "\n",
    "            acc_val = torch.eq(targets, outputs.round_()).float().mean();\n",
    "            epoch_accs_val += acc_val.item()\n",
    "            steps_val += 1\n",
    "            \n",
    "        val_acc = epoch_accs_val/steps_val\n",
    "        \n",
    "        val_loss = epoch_accs_val/steps_val\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    #print(\"loss:\", loss, \"acc:\", acc, \"val_acc:\", val_acc)\n",
    "    print('--------EPOCH SUMMARY---------')\n",
    "    print('Epoch ', e+1, ' training loss: ', loss)\n",
    "    print('Epoch ', e+1, ' training acc: ', acc*100, '%')\n",
    "    print('Epoch ', e+1, ' val acc: ', val_acc*100, '%')\n",
    "\n",
    "    # Comprueba EarlyStopping\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Deteniendo el entrenamiento temprano\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Graficar el error en entrenamiento y validación por época\n",
    "epochs_range = np.arange(1, e + 2)\n",
    "plt.plot(epochs_range, train_losses, label='Training Loss')\n",
    "plt.plot(epochs_range, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006937780046975741,\n",
       " 0.007909825412175988,\n",
       " 0.007170344552686138,\n",
       " 0.007452239913325156,\n",
       " 0.00666170927786058]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5578379956158724,\n",
       " 0.5820221449389602,\n",
       " 0.577797203352957,\n",
       " 0.5910547791105328,\n",
       " 0.596736597292351]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data_loader(texts, tokenizer, max_len, batch_size):\n",
    "    ds = TestDataset(\n",
    "        texts=texts.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "  )\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0 #cambie de 4 a 0 para evitar el posible error otra vez\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = create_test_data_loader(\n",
    "    commentDFVal_clean.text, \n",
    "    tokenizer,\n",
    "    max_secuence_length, \n",
    "    batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_organic(x):\n",
    "    if(x>=0.5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    \n",
    "    model = model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            \n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            \n",
    "        \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            outputs = torch.reshape(outputs, [outputs.shape[0]])\n",
    "            \n",
    "\n",
    "            outputs = [(is_organic(x)) for x in outputs]\n",
    "            outputs = [(preds.append(x)) for x in outputs]\n",
    "    \n",
    "#     print(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuestas(reales, predicciones):\n",
    "    contador_aciertos = 0\n",
    "    contador_no_aciertos = 0\n",
    "    for (real, prediccion) in zip(reales, predicciones):\n",
    "        if real == prediccion:\n",
    "            contador_aciertos = contador_aciertos+1\n",
    "        else:\n",
    "            contador_no_aciertos = contador_no_aciertos + 1\n",
    "    return contador_aciertos, contador_no_aciertos  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------EPOCH SUMMARY---------\n",
      "Epoch  1  training loss:  0.008469323958120039\n",
      "Epoch  1  training acc:  56.53174112560928 %\n",
      "Epoch  1  val acc:  57.29895107673876 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 5 \n",
    "train_the_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_preds = get_predictions(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentDFVal_clean['beto'] = label_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>beto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quieres saber lo que los escritores de esta pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Esta fue una pelcula muy bien guionadaGran div...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La pelcula no fue tan grandeEl libro es mejorP...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He tenido que cambiar mi opinin sobre la peor ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El mundo entero est cayendo presa de una enfer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Quin escribi el script para esta pelcula el pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Esta es la segunda pelcula que he visto de Ida...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Esta pelcula chupEl primero fue mucho mejorNad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Me encant esta pelcula lo vi cuando tena unos ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Admito que voy ms por el tradicional cuento de...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment  beto\n",
       "0    Quieres saber lo que los escritores de esta pe...          0     0\n",
       "1    Esta fue una pelcula muy bien guionadaGran div...          1     1\n",
       "2    La pelcula no fue tan grandeEl libro es mejorP...          1     1\n",
       "3    He tenido que cambiar mi opinin sobre la peor ...          0     0\n",
       "4    El mundo entero est cayendo presa de una enfer...          1     1\n",
       "..                                                 ...        ...   ...\n",
       "887  Quin escribi el script para esta pelcula el pe...          0     0\n",
       "888  Esta es la segunda pelcula que he visto de Ida...          1     1\n",
       "889  Esta pelcula chupEl primero fue mucho mejorNad...          0     0\n",
       "890  Me encant esta pelcula lo vi cuando tena unos ...          1     1\n",
       "891  Admito que voy ms por el tradicional cuento de...          1     1\n",
       "\n",
       "[892 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentDFVal_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileBETO = \"output_BETO\"\n",
    "commentDFVal_clean.to_csv(fileBETO, sep=',', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    545\n",
      "0    347\n",
      "Name: beto, dtype: int64\n",
      "892\n"
     ]
    }
   ],
   "source": [
    "print(commentDFVal_clean.beto.value_counts())\n",
    "print(len(commentDFVal_clean.beto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "aciertos, no_aciertos = respuestas(commentDFVal_clean.sentiment, label_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aciertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_aciertos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 epocas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jose/miniforge3/envs/myclone/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------EPOCH SUMMARY---------\n",
      "Epoch  1  training loss:  0.0043877327954897315\n",
      "Epoch  1  training acc:  78.01643924046589 %\n",
      "Epoch  1  val acc:  83.62470865249634 %\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 \n",
    "train_the_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_preds = get_predictions(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "aciertos, no_aciertos = respuestas(commentDFVal_clean.sentiment, label_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aciertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_aciertos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15 \n",
    "train_the_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_preds = get_predictions(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aciertos, no_aciertos = respuestas(commentDFVal_clean.sentiment, label_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
